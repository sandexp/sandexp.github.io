#### 基数查询

CBO根据统计信息和数学公式估算出来的，所以在看执行计划的时候，一定要注意嵌套循环驱动表的Rows是否估算准确，同时也要注意执行计划的入口Rows是否算错。

因为一旦嵌套循环驱动表的Rows估算错误，执行计划就错了。如果执行计划的入口Rows估算错误，那执行计划也就不用看了，后面全错。

#### 使用UNION替代OR

当SQL语句中同时有or和子查询，这种情况下子查询无法展开，只能走FILTER。遇到这种情况我们可以将SQL改写为union，从而消除FILTER。

如果无法改写SQL，那么SQL就只能走FILTER，这时我们需要在子查询表的连接列建立索引。

#### 分页优化

##### 单表分页优化

1. 排序列优化

   我们可以利用索引已经排序这个特性来优化分页语句，也就是说要将分页语句中的SORT ORDER BY消除。一般分页语句中都有排序。

   如果分页语句中有排序（order by），要利用索引已经排序特性，将order by的列包含在索引中，同时也要利用`rownum`的COUNT STOPKEY特性来优化分页SQL。

   如果分页中没有排序，可以直接利用`rownum`的COUNT STOPKEY特性来优化分页SQL。

2. 多个排序列处理

   如果排序列有多个列，创建索引的时候，我们要将所有的排序列包含在索引中，并且要注意排序列先后顺序（语句中是怎么排序的，创建索引的时候就对应排序），而且还要注意列是升序还是降序。

> 如果分页语句中排序列只有一个列，但是是降序显示的，创建索引的时候就没必要降序创建了，我们可以使用`HINT: index_desc`索引降序扫描就行。

3. 多个排序列+等值过滤+非等值过滤

   现在我们继续完善分页语句的优化思路：如果分页语句中有排序（order by），要利用索引已经排序特性，将order by的列按照排序的先后顺序包含在索引中，同时要注意排序是升序还是降序。

   如果分页语句中有过滤条件，我们要注意过滤条件是否有等值过滤条件，如果有等值过滤条件，要将等值过滤条件优先组合在一起，然后将排序列放在等值过滤条件后面，最后将非等值过滤列放排序列后面。

   如果分页语句中没有等值过滤条件，我们应该先将排序列放在索引前面，将非等值过滤列放后面，最后利用`rownum`的COUNT STOPKEY特性来优化分页SQL。

   如果分页中没有排序，可以直接利用`rownum`的COUNT STOPKEY特性来优化分页SQL。

4. 分区表处理

   如果分页语句中排序的表是分区表，这时我们要看分页语句中是否有跨分区扫描，如果有跨分区扫描，创建索引一般都创建为global索引，如果不创建global索引，就无法保证分页的顺序与索引的顺序一致。

##### 多表关联分页优化

多表关联分页语句，要利用索引已经排序特性、`ROWNUM`的COUNT STOPKEY特性以及嵌套循环传值特性来优化。

1. 多表关联分页语句，如果有排序，只能对其中一个表进行排序，

2. 让参与排序的表作为嵌套循环的驱动表，并且要控制驱动表返回的数据顺序与排序的顺序一致，其余表的连接列要创建好索引。

3. 如果有外连接，我们只能选择主表的列作为排序列，

4. 语句中不能有distinct、group by、max、min、avg、union、union all，执行计划中不能出现SORT ORDER BY。

#### 超大表和超小表连接查询

表a有30 MB，表b有30 GB，两表关联后返回大量数据，应该走HASH连接，因为a是小表所以a应该作为HASH JOIN的驱动表，大表b作为HASH JOIN的被驱动表。

因为被驱动表b特别大，想要加快SQL查询速度，必须开启并行查询。

超大表与超小表在进行并行HASH连接的时候，可以将小表（驱动表）广播到所有的查询进程，然后对大表进行并行随机扫描，每个查询进程查询部分b表数据，然后再进行关联。

> 怎么才能让a表进行广播呢？我们需要添加`hint：pq_distribute`

#### 超大表和超大表连接查询

##### 较小规模大表的连接查询

表a有4 GB，表b有6 GB，两表关联后返回大量数据，应该走HASH连接。因为a比b小，所以a表应该作为HASH JOIN的驱动表。驱动表a有4 GB，需要放入PGA中。因为PGA中work area不能超过2 G，所以PGA不能完全容纳下驱动表，这时有部分数据会溢出到磁盘（TEMP）进行on-disk hash join。

超大表与超大表在进行并行HASH连接的时候，需要将两个表根据**连接列进行HASH运算**，然后将运算结果放到PGA中，**再进行HASH连接**，这种并行HASH连接就叫作并行HASH HASH连接。(也就是说PGA中存储的是连接了的哈希值，不是实体数据).

> 怎么写HINT实现并行HASH HASH呢？我们需要添加`hint：pq_distribute`（被驱动表hash,hash）。

例如:

```sql
select * from a,b where a.object_id=b.object_id;
```

假设对上面SQL启用6个并行查询，a表会根据连接列进行HASH运算然后拆分为6份，记为`a1，a2，a3，a4，a5，a6`，b表也会根据连接列进行HASH运算然后拆分为6份，记为`b1，b2，b3，b4，b5，b6`。



##### 超大规模大表的连接查询

如果表a有20 G，表b有30 G，即使采用并行HASH HASH连接也很难跑出结果，因为要把两个表先映射到PGA中，这需要耗费一部分PGA，之后在进行HASH JOIN的时候也需要部分PGA，此时PGA根本就不够用.

> 如何解决超级大表（几十GB）与超级大表（几十GB）关联的性能问题呢？我们可以根据并行HASH HASH关联的思路，人工实现并行HASH HASH。

在表a的结构上添加一个字段HASH_VALUE，同时根据HASH_VALUE进行LIST分区。（就是建立分区表，分区表并行执行）。

#### DBLINK 优化

现在有如下两个表，a表是远端表（1800万），b表是本地表（100行）。

远端表a很大，对数据进行传输会耗费大量时间，本地表b表很小，而且a和b关联之后返回数据量很少，我们可以将本地表b传输到远端，在远端进行关联，然后再将结果集传回本地，这时需要使用`hint：driving_site`.

##### 两个大表DBLINK 处理

如果远端表a很大，本地表b也很大，两表关联返回数据量多，这时既不能将远端表a传到本地，也不能将本地表b传到远端，因为无论采用哪种方法，SQL都很慢。我们可以在本地创建一个带有 dblink 的物化视图，将远端表a的数据刷新到本地，然后再进行关联。

#### 对表进行切片

对一个很大的分区表进行UPDATE、DELETE，想要加快执行速度，可以按照分区，在不同的会话中对每个分区单独进行UPDATE、DELETE。但是对一个很大的非分区表进行UPDATE、DELETE，如果只在一个会话里面运行SQL，很容易引发UNDO不够，如果会话连接中断，会导致大量数据从UNDO回滚，这将是一场灾难。



对于非分区表，我们可以对表按照ROWID切片，然后开启多个窗口同时执行SQL，这样既能加快执行速度，还能减少对UNDO的占用。

上述方法需要手动编辑大量SQL脚本，如果表的Extent很多，这将带来大工作量。我们可以编写存储过程简化上述操作。

#### SQL三段分拆法

上述方法需要手动编辑大量SQL脚本，如果表的Extent很多，这将带来大工作量。我们可以编写存储过程简化上述操作。即:

```sql
select 第一段 from 第二段 where 第三段
```

需要注意以下几点:

1. select与from之间最好不要有标量子查询，也不要有自定义函数。因为有标量子查询或者是自定义函数，会导致子查询或者函数中的表被反复扫描。
2. from与where之间要关注大表，因为大表很容易引起性能问题；同时要留意子查询和视图，如果有子查询或者视图，要单独运行，看运行得快或是慢，如果运行慢需要单独优化；另外要注意子查询/视图是否可以谓词推入，是否会视图合并；最后还要留意表与表之间是内连接还是外连接，因为外连接会导致嵌套循环无法改驱动表。
3. where后面需要特别注意子查询，要能判断各种子查询写法是否可以展开，同时也要注意where过滤条件，尽量不要在where过滤列上使用函数，这样会导致列不走索引。