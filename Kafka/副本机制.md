多副本机制是分布式系统中保证数据一致性的常规做法，下面探讨一下Kafka实现的多副本机制实现细节。

#### Kafka多副本机制

数据副本是指在不同节点上持久化同一份数据，当某个节点宕机的时候，可以从其他副本上同步数据，从而恢复副本状态。Kafka对于副本机制设计了AR，ISR， HW，LEO的概念。

下面简单介绍一些这四个参数：

+ AR: 系统中所有的副本信息
+ ISR: 系统中保持与leader副本同步的副本信息
+ HW：高水位线, 表示当前以及提交的最大偏移量位置，即主从副本都将这之前的数据提交完毕，并且得到确认,也是ISR集合中最小的LEO值
+ LEO: 分区末尾的下一条消息偏移量, 用于指示当前分区读写指针的位置

##### 失效副本

在AR范围内，且在ISR范围之外的副本信息，我们称作为失效副本，存储在OSR中。

当一个副本超过一个给定时间没有与leader副本进行同步，当前副本就会被标记为失效副本。则将其移除ISR，如果一个宕机的节点恢复的时候，会尝试与leader副本同步数据，当同步到HW的时候，视为追上了leader副本，将其加入ISR中。

常见的副本失效原因:

1. follower由于进行频繁的`full gc` 导致无法与leader进行有效的连接
2. IO开销过大，导致超出了限定时间

#### ISR集合变化的影响

当ISR集合元素进行变化的时候，任意副本的LEO的变化都会可能影响HW的变化。

副本包括本地副本和远程副本两种类型，同一个分区的节点会分布在各个broker节点上，主要是用于容错。follower通过RPC获取leader发送过来的日志同步消息，并将leader写入的新日志追加到自己的本地日志中。

#### Leader Epoch

leader epoch的引用主要是用于解决leader切换的时候出现的同步问题。其中每次leader变更一次，epoch值就会加一。

新的leader副本选择为ISR列表中，具有最大LEO的副本信息，其他副本复制与这个副本保持一致，当挂掉的leader恢复的时候，且LEO大于新的leader的LEO，那么这个副本就会被截断，并重新写入副本日志信息。

#### 为什么不使用读写分离减小节点负载压力

Kafka对于消息的生产和消费都是又leader副本进行处理的，实现上是一种主写主度的方式。

1. 读写分离会在副本同步的过程中造成数据一致性问题
2. 读写分离在数据复制过程中由于数据的网络传输会造成延迟
3. Kafka如果使用读写分离的方式，则不容易进行负载均衡，设计的时候是根据leader副本的位置进行负载均衡的，如果考虑到读写分离，则需要将读写操作都考虑进来，并衡量需要服务的副本是哪个，比较麻烦。

#### 日志同步机制

分布式系统中既要保证数据的一致性，也要保证数据的顺序性。如果leader宕机的时候，则需要选举一个新的leader来作为数据同步的标准。

常用的选举协议由Zab，Raft, 需要容错集群至少一半以上的失效副本，选举开销比较大。

Kafka使用了ISR集合，维护了可用副本信息，在这之中选择LEO最大的即可。当然也可以设置从AR中选择，不过这个时候会出现同步性能的开销增大以及截断日志情况的频繁发生。

