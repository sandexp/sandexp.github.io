#### 文件目录布局

Kafka消息按照主题进行分类，每个主题中有多个分区，消息在分区中以偏移量的信息来定位。

在不考虑多副本的情况下，一个分区对应于一个日志文件，为了保证日志文件的大小不会过大，这里需要引入日志分段的概念，将日志进行划分，对于每个日志分段，包含有日志文件和索引文件信息。索引文件支持按照偏移量的索引以及按照时间戳信息。

为了提升IO效率，日志文件的写入只支持追加模式(即顺序写入,减少磁盘寻道开销). 最后一个写入的日志片段称作激活分段，当激活分段写满了，则会新建一个激活片段写入。

#### 日志索引

Kafka中日志索引文件有两类，一类是以偏移量为寻址目标的索引文件，另一类是以时间戳为寻址目标的索引文件。Kafka中使用的是稀疏索引，并不是每次写入一条消息，就会为这个消息建立索引，而是每写入一批数据，才会写入索引信息。

所以很有可能查找的偏移量或者时间戳，索引文件中没有与其相等的记录。因此我们需要通过二分查找的方式，查找其写入的批次信息，获取批次的首地址，再进行寻址操作。

##### 偏移量索引

索引文件有一个固定的12 B的头部信息，前8 B表示相对偏移量，后4 B表示消息在日志分段中的位置。

##### 时间戳索引

索引文件有一个固定的12 B的头部信息，前8 B表示当前分段的最大时间戳，后4 B表示消息在日志分段中的位置。

#### 日志清理

为了控制大量日志数据占有磁盘空间，Kafka需要设定合理的日志清理方式。

##### 日志删除

按照一定规则保留日志记录，其他日志记录删除。

Kafka日志管理器会启用一个线程，周期性地检查不符合保留条件的日志记录。主要可以基于以下几个方面:

1. 时间
2. 偏移量
3. 日志大小

##### 日志合并

针对于每个key的消息进行整合，保留key的最新版本数据。

日志合并前后，消息的偏移量信息保持不变，只是被合并的那部分消息不可查找到而已，这个过程会生成新的分段文件，所以这样来说偏移量信息不再是连续的。

利用日志合并技术可以快速的恢复系统的状态机。

#### 磁盘存储优化

1. 顺序写

   Kafka只支持在末尾添加记录的方式，目的是支持磁盘顺序写，顺序写要比随机写性能要高。

2. 页缓存

   使用页缓存可以减少操作系统进行中断换页的频率，当且仅当页缓存未命中的时候才需要申请中断。操作系统会在系统内部脏页率到达一定数值的时候，将脏页刷写到磁盘中。

3. 零拷贝

   利用DMA技术将磁盘文件直接拷贝到网卡中发送，实际上如果采用正常的数据发送方式，现需要将数据拷贝到本地主存，然后从本地主存拷贝到网卡设备(Socket)中. 

   零拷贝技术节省了两次对象的拷贝过程，对于大对象的性能比较高。

##### 磁盘IO调度算法

Linux系统下默认的磁盘IO调度策略分为如下几类:

1. NOOP

   无任何动作，采样FIFO队列的方式提供服务,会对相邻的IO请求做合并.

2. CFQ

   完全公平调度: 将IO的物理地址进行排序，然后按照这个顺序进行IO调度，减小磁盘调度开销.

   但是会导致某个比较靠后的地址IO请求被饿死的情况出现.

3. DEADLINE

   在CFQ的基础上解决了请求被饿死的问题, DEADLINE策略中，除了维护FIFO队列，还维护了读写的队列，对读请求的优先度高于写请求，同时高于CFQ的调度请求.

4. ANTICIPATORY

   对连续IO的优化策略,通过付出时间代价(等待一段时间)，获取尽可能多的连续IO流，将其合并成一个大的IO流进行处理.